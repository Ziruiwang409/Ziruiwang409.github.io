<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Zirui Wang</title>

    <meta name="author" content="Zirui Wang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Zirui Wang
                </p>
                <p>I am a second-year master student at the University of Illinois at Urbana-Champaign, advised by Prof. <a href="https://rehg.org/">James M. Rehg</a>. Previously, I got my
                  Bachelor's degree in Computer Science from University of Illinois at Urbana-Champaign under the supervision of Prof.
                  <a href="https://slazebni.cs.illinois.edu/">Svetlana Lazebnik</a>. My research interest lies in 3D/4D Reconstructions and 3D Generative Models. 
                </p>
                <p style="text-align:center">
                  <a href="mailto:ziruiw3@illinois.edu">Email</a> &nbsp;/&nbsp;
                  <a href="https://github.com/Ziruiwang409/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/zirui-wang-b86364223/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:30%">
                <a href="images/profile_photo.jpg"><img style="width:100%;max-width:100%;" alt="profile photo" src="images/profile_photo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <!-- <p>
                  My research interest lies in 3D vision and Robotics (Embodied AI). 
                  I'm also intrigued by the emerging properties of multimodal large language models 
                  and hope to adapt them to new and existing downstream tasks in 3D domain. 
                </p> -->
              </td>
            </tr>
          </tbody></table>
          <!-- Cue3D -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:30%;vertical-align:middle">
                <div class="one">
                  <img src='images/research/cue3d/cues.png' width="215"></div>
                </div>
              </td>
              <td style="padding:20px;width:70%;vertical-align:top">
                <span class="papertitle">Cue3D: Quantifying the Role of Image Cues in Single-Image 3D Generation</span>
                <br>
                  <a href="https://ryanxli.github.io/" target="_blank">Xiang Li*</a>,
                  <strong>Zirui Wang*</strong>,
                  <a href="https://zixuanh.com/" target="_blank">Zixuan Huang</a>,
                  <a href="https://rehg.org/" target="_blank">James M. Rehg</a>
                <br>
                <em>NeurIPS</em>, 2025 (Spotlight)
                <br>
                [<a href="./assets/cue3d.pdf" target="_blank">Paper</a>]
                [<a href="https://ryanxli.github.io/cue3d/index.html" target="_blank">Project Page</a>]
                <p></p>
                <p>
                  We introduce Cue3D, the first comprehensive, model-agnostic framework for quantifying the influence of individual image cues in single-image 3D generation.
                </p>
              </td>
            </tr>
          </tbody></table>
          <!-- HiMemFormer -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:30%;vertical-align:middle">
                <div class="one">
                  <img src='images/research/himemformer/HiMemFormer.png' width="215"></div>
                </div>
              </td>
              <td style="padding:20px;width:70%;vertical-align:top">
                <span class="papertitle">HiMemFormer: Hierarchical Memory-Aware Transformer for Multi-Agent Action Anticipation</span>
                <br>
                  <strong>Zirui Wang</strong>,
                  <a href="https://colinzhaoust.github.io/" target="_blank">Xinran Zhao</a>,
                  <a href="https://simonstepputtis.com/" target="_blank">Simon Stepputtis</a>,
                  <a href="https://sites.google.com/view/wjkim1202/%ED%99%88" target="_blank">Woojun Kim</a>,
                  <a href="https://www.cs.cmu.edu/~sherryw/" target="_blank">Tongshuang Wu</a>,
                  <a href="https://www.cs.cmu.edu/~sycara/" target="_blank">Katia P. Sycara</a>,
                  <a href="https://yaqi-xie.me/" target="_blank">Yaqi Xie</a>
                <br>
                <em>NeurIPS Workshop on Video-Language Models</em>, 2024
                <br>
                [<a href="https://arxiv.org/abs/2411.01455" target="_blank">Paper</a>]
                <p></p>
                <p>
                  We propose the Hierarchical Memory-Aware Transformer (HiMemFormer), a novel approach that simultaneously learns feature
                  representations from both contextual and agent-specified dimensions through a dual-hierarchical framework.
                </p>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Teaching</h2>
                <br>
                <a href="https://slazebni.cs.illinois.edu/spring25/">CS444: Deep Learning for Computer Vision, Spring 2025</a>
                <br>
                <a href="https://courses.grainger.illinois.edu/cs440/fa2024/">CS440/ECE448: Artificial Intelligence, Fall 2024</a>
                <br>
                <a href="https://publish.illinois.edu/safe-autonomy/home-spring-2024-2/">ECE484: Principle of Safe Autonomy, Spring 2024</a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Last Update in October, 2025. Thanks for the amazing template from <a href="https://jonbarron.info/">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
